{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQB6jUVevZRb"
   },
   "source": [
    "# Three learning algorithms\n",
    "\n",
    "**Author: Diana Mateus**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alKP72LX0DnN"
   },
   "source": [
    "\n",
    "Scikit-learn is a very popular Machine Learning library for Python. In this notebook we will study how to put in practice the the three simple machine learning models \n",
    "\n",
    "*   Linear Regression\n",
    "*   K-nearest neighbors\n",
    "*   Naive Bayes \n",
    "\n",
    "\n",
    "**GOALS**: \n",
    "\n",
    "*   Understanding the purpose of data splitting in Machine Learning\n",
    "*   Experimenting the train, val and test schemes with existing model from the scikit library\n",
    "*   Evaluating a binary classification or a regression ML approach\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7l9znFXqw3h"
   },
   "source": [
    "## 0. Importing Modules and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following lines to load the modules required for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Vy_xMsgDq0jx"
   },
   "outputs": [],
   "source": [
    "import numpy as np #scientific computing (in ML it handles and operates on multi-dimensional arrays)\n",
    "import matplotlib.pyplot as plt #for data visualization\n",
    "import sklearn #for Machine Learning\n",
    "import pandas as pd #for reading, writing and processing databases \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GeEfQr-WraKX"
   },
   "source": [
    "### Loading and Splitting Data\n",
    "\n",
    "Remember that the objective of a Supervised Machine Learning methods is\n",
    "\n",
    "*   to learn from examples\n",
    "*   how to make predictions\n",
    "*   for unseen data!!! (Generalization)\n",
    "\n",
    "To train a supervised learning model we need an annotated dataset. The dataset is often a matrix $X$ of dimensions NxD, with N  the number of points/samples and $D$ the dimensionality of the vector describing *one* sample.\n",
    "\n",
    "We need part of the data to train the model parameters. Moreover, if the model has hyperparameters (non trainable parameters) their tunning should be done on a different subset of the data. Finally, to verify that the model generalises well, it is important to evaluate its performance on unseen data (not used for training nor validation). For the above reasons necessary to split the data matrix into three groups:\n",
    "*  **Training set** : used to fit the model parameters.\n",
    "*  **Validation set** : used to set the model hyper-parameters.\n",
    "*  **Test set** : used only after training and validation have been finished to evaluate the performance of the method.\n",
    "\n",
    "For real life problems is important to reduce the use of the test set to its minimum, to improve generalization.\n",
    "\n",
    "**What to do**: Run the following sections to load and split two datasets: one for regression and one for classification. Explore and change the code lines to understand the dataset dimension and how to split it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zyK0InZ2N3b"
   },
   "source": [
    "### Datasets for Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IRYBPKoXtRNg",
    "outputId": "18580ba5-483e-4ff0-b1ca-4d84c23a71de"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets \n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "# Explore on your own the dimensions of the dataset and their meaning. \n",
    "print('The full data matrix has shape',diabetes.data.shape)\n",
    "\n",
    "X = diabetes.data[:, np.newaxis, 2] \n",
    "\n",
    "# Splitting the data matrix\n",
    "X_train = X[:-30]\n",
    "X_test = X[-30:]\n",
    "y_train = diabetes.target[:-30]\n",
    "y_test = diabetes.target[-30:]\n",
    "\n",
    "# Explore the data\n",
    "#print(diabetes.DESCR) #Comment/Uncomment to see the dataset description\n",
    "print('Dimension of the feature vector', diabetes.feature_names)\n",
    "print('Dimension of the target value',diabetes.target.shape)\n",
    "print('X train', X_train.shape)\n",
    "print('X test',X_test.shape)\n",
    "print('y train',y_train.shape)\n",
    "print('y test',y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBlpHylU7cbZ"
   },
   "source": [
    "### Datasets for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GwPqKKx8rZ2U",
    "outputId": "6c3bd091-6493-4f86-e178-2e7947347d27",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "\n",
    "label_names = data['target_names']\n",
    "labels = data['target']\n",
    "feature_names = data['feature_names']\n",
    "features = data['data']\n",
    "\n",
    "print(label_names)\n",
    "print(labels.shape)\n",
    "print(feature_names)\n",
    "print(features.shape)\n",
    "#print(data.DESCR) #Comment/Uncomment to see or hide the dataset description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following scikit function splits the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_nRhb-PHruH9"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(features,labels,test_size = 0.40, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8bb5p0PqVv0"
   },
   "source": [
    "# 1. Training a ML model\n",
    "\n",
    "When relying with on the scikit library, training a model is very simple. You  need to:\n",
    "*   Load the model from scikit\n",
    "*   Declare a new instance of the model \n",
    "*   Train the model parameters\n",
    "*   Make predictions for new data\n",
    "*   Evaluate the performance\n",
    "\n",
    "Identify in the example code the above steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQZxSTfNAY5T"
   },
   "source": [
    "\n",
    "### Model 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tqUdMUhttNL0"
   },
   "outputs": [],
   "source": [
    "#Load and declare a new instance \n",
    "from sklearn import linear_model\n",
    "regr = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PyaY_YzU9oUY",
    "outputId": "ee80b31c-9020-4cdd-e3ab-56281e436370"
   },
   "outputs": [],
   "source": [
    "#Fit (train) the model \n",
    "regr.fit(X_train, y_train)\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "print('Intercept: \\n', regr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Psq8bTAL9oCq"
   },
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8bJhCgqX__rk",
    "outputId": "f9cf94c4-0e6f-4efb-c0cf-79016b00e8c1"
   },
   "outputs": [],
   "source": [
    "#Evaluate the performance\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "_jgPq4a-9po-",
    "outputId": "846e5478-3f98-4bdb-97be-dc23243e7ae4"
   },
   "outputs": [],
   "source": [
    "#Visualize \n",
    "plt.scatter(X_test, y_test, color='blue')\n",
    "plt.plot(X_test, y_pred, color='red', linewidth=3)\n",
    "plt.xlabel('bmi')\n",
    "plt.ylabel('diabetes progression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMLpS4k1qZC0"
   },
   "source": [
    "## Model 2. K-Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "45Ma2BaVsqIF",
    "outputId": "951ea8eb-605d-4f77-f0cc-763c1146acc9"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knnClassifier = KNeighborsClassifier(n_neighbors=2)\n",
    "knnClassifier.fit(X2_train, y2_train)\n",
    "y2_pred_knn = knnClassifier.predict(X2_test)\n",
    "print(y2_pred_knn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EvDv8enObTc2",
    "outputId": "703c0cee-d78e-4575-a510-2ae39f6cf1e1"
   },
   "outputs": [],
   "source": [
    "#Compute accuracy on the training set\n",
    "train_accuracy = knnClassifier.score(X2_train, y2_train)\n",
    "    \n",
    "#Compute accuracy on the test set\n",
    "test_accuracy = knnClassifier.score(X2_test, y2_test) \n",
    "\n",
    "print('train accuracy', train_accuracy)\n",
    "print('test accuracy',test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Uy3nUkjqdNl"
   },
   "source": [
    "## Model 3. Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yEkGgcgUqn_K",
    "outputId": "12903e0d-6048-4804-c396-6a3eeb82237e"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnbClassifier = GaussianNB()\n",
    "gnbClassifier.fit(X2_train,y2_train)\n",
    "y2_pred_gnb = gnbClassifier.predict(X2_test)\n",
    "print(y2_pred_gnb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1uU7olRcdpM",
    "outputId": "e44b868f-d149-4c2e-a404-45b8b7025bde"
   },
   "outputs": [],
   "source": [
    "#Compute accuracy on the training set\n",
    "train_accuracy = gnbClassifier.score(X2_train, y2_train)\n",
    "    \n",
    "#Compute accuracy on the test set\n",
    "test_accuracy = gnbClassifier.score(X2_test, y2_test) \n",
    "\n",
    "print('train accuracy', train_accuracy)\n",
    "print('test accuracy',test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iftgXOiztm1y"
   },
   "source": [
    "# QUESTIONS\n",
    "\n",
    "\n",
    "\n",
    "1.   In the regression example and keeping the size of the test set fixed, what is the effect on the (test) performance when we progressively increase the amount of training data? Demonstrate with performane plots and discuss.\n",
    "2.   In the linear regression example and keeping the size of the test set fixed, what is the effect of using other varaibles other than the  'bmi' used during training?, is it using more information always better? (try adding new features, report results and discuss the results).\n",
    "3.   In the above examples, we have split each dataset into two subsets each. Are two subsets (train and test) enough for the three models (lin reg, KNN, NaiveBayes)? Answer for each model.\n",
    "4.   Repeat the KNN example, but splitting the dataset into three subsets(train,val,test). Progressively modify the hyperparameter k.  What is the best neighborhood size k?, what is the appropriate methodologogy to find this number? \n",
    "5.   How do we know if learning was really succesful (vs underfitting or overfitting?)\n",
    "7. What is the highest performance you can achieve for the two classification methods? What model for classification is better?, why?\n",
    "8.   Naive classifiers are probabilistic classifiers. How do we recover the probabilistic information associated to this model? What quantities can we recover?\n",
    "9.   How is the performance score computed? create a function that calculates the TP, TN, FP and FN and replace the in-built score function with your own. Provide this code into the report. \n",
    "10.   We saw in the lecture that linear models were used for regression, while KNN and Naive Bayes were used for classification. Can we use linear models for classification?  KNN or Naive Bayes for regression problems?\n",
    "\n",
    "**BONUS**\n",
    "Implement your own version of one of the three algorithms and compare the results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kzbylb5UeWQn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LEARN-LAB-1-solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
